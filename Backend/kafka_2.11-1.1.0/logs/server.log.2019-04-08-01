[2019-04-08 02:09:29,727] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-08 02:14:58,450] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Found deletable segments with base offsets [176] due to retention time 1000ms breach (kafka.log.Log)
[2019-04-08 02:14:58,456] INFO [ProducerStateManager partition=course_available-0] Writing producer snapshot at offset 177 (kafka.log.ProducerStateManager)
[2019-04-08 02:14:58,460] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Rolled new log segment at offset 177 in 8 ms. (kafka.log.Log)
[2019-04-08 02:14:58,460] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Scheduling log segment [baseOffset 176, size 159] for deletion. (kafka.log.Log)
[2019-04-08 02:14:58,462] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Incrementing log start offset to 177 (kafka.log.Log)
[2019-04-08 02:14:58,468] INFO Cleared earliest 0 entries from epoch cache based on passed offset 177 leaving 1 in EpochFile for partition course_available-0 (kafka.server.epoch.LeaderEpochFileCache)
[2019-04-08 02:15:58,465] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Deleting segment 176 (kafka.log.Log)
[2019-04-08 02:15:58,467] INFO Deleted log /tmp/kafka-logs/course_available-0/00000000000000000176.log.deleted. (kafka.log.LogSegment)
[2019-04-08 02:15:58,467] INFO Deleted offset index /tmp/kafka-logs/course_available-0/00000000000000000176.index.deleted. (kafka.log.LogSegment)
[2019-04-08 02:15:58,468] INFO Deleted time index /tmp/kafka-logs/course_available-0/00000000000000000176.timeindex.deleted. (kafka.log.LogSegment)
[2019-04-08 02:19:29,741] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-08 02:29:29,758] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-08 02:29:36,650] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions enroll-0 (kafka.server.ReplicaFetcherManager)
[2019-04-08 02:29:36,656] INFO [Log partition=enroll-0, dir=/tmp/kafka-logs] Loading producer state from offset 0 with message format version 2 (kafka.log.Log)
[2019-04-08 02:29:36,657] INFO [Log partition=enroll-0, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-04-08 02:29:36,659] INFO Created log for partition enroll-0 in /tmp/kafka-logs with properties {compression.type -> producer, message.format.version -> 1.1-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-04-08 02:29:36,666] INFO [Partition enroll-0 broker=0] No checkpointed highwatermark is found for partition enroll-0 (kafka.cluster.Partition)
[2019-04-08 02:29:36,667] INFO Replica loaded for partition enroll-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-04-08 02:29:36,667] INFO [Partition enroll-0 broker=0] enroll-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-04-08 02:29:36,668] INFO [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List() (kafka.server.ReplicaAlterLogDirsManager)
[2019-04-08 02:30:08,967] INFO Updated PartitionLeaderEpoch. New: {epoch:0, offset:0}, Current: {epoch:-1, offset:-1} for Partition: enroll-0. Cache now contains 0 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-04-08 02:34:58,479] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Found deletable segments with base offsets [177] due to retention time 1000ms breach (kafka.log.Log)
[2019-04-08 02:34:58,496] INFO [ProducerStateManager partition=course_available-0] Writing producer snapshot at offset 178 (kafka.log.ProducerStateManager)
[2019-04-08 02:34:58,498] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Rolled new log segment at offset 178 in 8 ms. (kafka.log.Log)
[2019-04-08 02:34:58,499] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Scheduling log segment [baseOffset 177, size 159] for deletion. (kafka.log.Log)
[2019-04-08 02:34:58,500] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Incrementing log start offset to 178 (kafka.log.Log)
[2019-04-08 02:34:58,503] INFO Cleared earliest 0 entries from epoch cache based on passed offset 178 leaving 1 in EpochFile for partition course_available-0 (kafka.server.epoch.LeaderEpochFileCache)
[2019-04-08 02:35:58,502] INFO [Log partition=course_available-0, dir=/tmp/kafka-logs] Deleting segment 177 (kafka.log.Log)
[2019-04-08 02:35:58,503] INFO Deleted log /tmp/kafka-logs/course_available-0/00000000000000000177.log.deleted. (kafka.log.LogSegment)
[2019-04-08 02:35:58,504] INFO Deleted offset index /tmp/kafka-logs/course_available-0/00000000000000000177.index.deleted. (kafka.log.LogSegment)
[2019-04-08 02:35:58,504] INFO Deleted time index /tmp/kafka-logs/course_available-0/00000000000000000177.timeindex.deleted. (kafka.log.LogSegment)
[2019-04-08 02:39:29,772] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-08 02:49:29,789] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-04-08 02:59:29,801] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
